{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nimport pandas as pd\\nimport mysql.connector\\n\\n# Database connection parameters\\nhost = \"your_host\"\\nport = 3306  # default MySQL port\\nuser = \"your_username\"\\npassword = \"your_password\"\\ndatabase = \"your_database_name\"\\n\\n# Establishing the connection\\nconn = mysql.connector.connect(host=host, port=port, user=user, password=password, database=database)\\n\\n# SQL query\\nquery = \"SELECT column1, column2, column3 FROM your_table_name\"\\n\\n# Fetching data into DataFrame\\ndf = pd.read_sql(query, conn)\\n\\n# Renaming columns if necessary\\ndf.rename(columns={\\'Participants\\': \\'label\\'}, inplace=True)\\n\\n# Display the first few rows of the DataFrame\\nprint(df.head())\\n\\n# Close the connection\\nconn.close()\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(\"dataset2.csv\")\n",
    "df.rename(columns = {'UserID':'label',}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the reading is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>NewUser</th>\n",
       "      <th>Username</th>\n",
       "      <th>Email</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ActivityLevel</th>\n",
       "      <th>GoalID</th>\n",
       "      <th>DietPreferenceID</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>AllergenID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28001</td>\n",
       "      <td>True</td>\n",
       "      <td>Robert Clark</td>\n",
       "      <td>robert.clark@example.com</td>\n",
       "      <td>Other</td>\n",
       "      <td>57</td>\n",
       "      <td>192</td>\n",
       "      <td>87</td>\n",
       "      <td>Sedentary</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28002</td>\n",
       "      <td>False</td>\n",
       "      <td>Stephanie White</td>\n",
       "      <td>stephanie.white@example.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>62</td>\n",
       "      <td>183</td>\n",
       "      <td>100</td>\n",
       "      <td>Very Active</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28003</td>\n",
       "      <td>True</td>\n",
       "      <td>Amanda Davis</td>\n",
       "      <td>amanda.davis@hotmail.com</td>\n",
       "      <td>Other</td>\n",
       "      <td>45</td>\n",
       "      <td>189</td>\n",
       "      <td>61</td>\n",
       "      <td>Active</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28004</td>\n",
       "      <td>False</td>\n",
       "      <td>Catherine Mitchell</td>\n",
       "      <td>catherine.mitchell@gmail.com</td>\n",
       "      <td>Other</td>\n",
       "      <td>65</td>\n",
       "      <td>178</td>\n",
       "      <td>56</td>\n",
       "      <td>Very Active</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28005</td>\n",
       "      <td>True</td>\n",
       "      <td>Donna Hill</td>\n",
       "      <td>donna.hill@hotmail.com</td>\n",
       "      <td>Other</td>\n",
       "      <td>46</td>\n",
       "      <td>185</td>\n",
       "      <td>111</td>\n",
       "      <td>Moderately Active</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  NewUser            Username                         Email  Gender  \\\n",
       "0  28001     True        Robert Clark      robert.clark@example.com   Other   \n",
       "1  28002    False     Stephanie White   stephanie.white@example.com  Female   \n",
       "2  28003     True        Amanda Davis      amanda.davis@hotmail.com   Other   \n",
       "3  28004    False  Catherine Mitchell  catherine.mitchell@gmail.com   Other   \n",
       "4  28005     True          Donna Hill        donna.hill@hotmail.com   Other   \n",
       "\n",
       "   Age  Height  Weight      ActivityLevel  GoalID  DietPreferenceID  RegionID  \\\n",
       "0   57     192      87          Sedentary       5                 3         5   \n",
       "1   62     183     100        Very Active       2                 6         6   \n",
       "2   45     189      61             Active       3                 8         3   \n",
       "3   65     178      56        Very Active       4                 4        10   \n",
       "4   46     185     111  Moderately Active      10                 7         6   \n",
       "\n",
       "   AllergenID  \n",
       "0          10  \n",
       "1          10  \n",
       "2           1  \n",
       "3           6  \n",
       "4           9  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Columns to Text for NLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns_to_text(df, exclude_columns=None, column_weights=None):\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    if column_weights is None:\n",
    "        column_weights = {}\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=['text', 'label'])\n",
    "    \n",
    "    # Store the 'label' column if it exists and is not in the exclude list\n",
    "    label_col = df['label'] if 'label' in df.columns and 'label' not in exclude_columns else None\n",
    "    \n",
    "    # Drop the columns that need to be excluded\n",
    "    df_combined = df.drop(columns=exclude_columns, errors='ignore')\n",
    "    \n",
    "    # Apply weighting to specified columns by repeating their contents along with the column name\n",
    "    for column, weight in column_weights.items():\n",
    "        if column in df_combined.columns:\n",
    "            df_combined[column] = df_combined[column].apply(\n",
    "                lambda x: (' '.join([f\"{column}:{x}\"] * weight)) if pd.notnull(x) else ''\n",
    "            )\n",
    "    \n",
    "    # Combine all columns into a single column\n",
    "    df_combined['text'] = df_combined.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "    \n",
    "    # Include the 'label' column in the result if it was stored\n",
    "    if label_col is not None:\n",
    "        df_combined['label'] = label_col\n",
    "    \n",
    "    # Return the DataFrame with the 'text' and 'label' columns\n",
    "    return df_combined[['text', 'label']] if label_col is not None else df_combined[['text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpler version of combining for later evaluation of text similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns_to_text_simple(df, exclude_columns=None):\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=['text', 'label'])\n",
    "    \n",
    "    # Store the 'label' column if it exists and is not in the exclude list\n",
    "    label_col = df['label'] if 'label' in df.columns and 'label' not in exclude_columns else None\n",
    "    \n",
    "    # Drop the columns that need to be excluded\n",
    "    df_combined = df.drop(columns=exclude_columns, errors='ignore')\n",
    "    \n",
    "    # Combine column names and values into a single column by concatenating the text from each column with its column name\n",
    "    df_combined['text'] = df_combined.apply(lambda row: ' '.join([f\"{col}:{val}\" for col, val in row.dropna().items()]), axis=1)\n",
    "    \n",
    "    # Include the 'label' column in the result if it was stored\n",
    "    if label_col is not None:\n",
    "        df_combined['label'] = label_col\n",
    "    \n",
    "    # Return the DataFrame with the 'text' and 'label' columns\n",
    "    return df_combined[['text', 'label']] if label_col is not None else df_combined[['text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting importance/weights of the parameters in te text\n",
    "- by adding more textual signifigance to the data for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for each column\n",
    "column_weights = {\n",
    "    'Username': 0,\n",
    "    'Email': 0,\n",
    "    'Gender': 0,\n",
    "    'Age': 0,\n",
    "    'Height': 0,\n",
    "    'Weight': 0,\n",
    "    'ActivityLevel': 15,\n",
    "    'GoalID': 10,\n",
    "    'DietPreferenceID': 15,\n",
    "    'RegionID': 15,\n",
    "    'AllergenID': 30  # Higher weight for AllergenID\n",
    "}\n",
    "\n",
    "# Combine columns with specified weights\n",
    "generalDataframe = combine_columns_to_text(df, exclude_columns=['DietID'], column_weights=column_weights)\n",
    "generalDataframe2=combine_columns_to_text_simple(df,exclude_columns=['DietID','Email','Username'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the format is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28001 True     192  ActivityLevel:Sedentary Ac...</td>\n",
       "      <td>28001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28002 False     183  ActivityLevel:Very Active...</td>\n",
       "      <td>28002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28003 True     189  ActivityLevel:Active Activ...</td>\n",
       "      <td>28003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28004 False     178  ActivityLevel:Very Active...</td>\n",
       "      <td>28004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28005 True     185  ActivityLevel:Moderately A...</td>\n",
       "      <td>28005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  28001 True     192  ActivityLevel:Sedentary Ac...  28001\n",
       "1  28002 False     183  ActivityLevel:Very Active...  28002\n",
       "2  28003 True     189  ActivityLevel:Active Activ...  28003\n",
       "3  28004 False     178  ActivityLevel:Very Active...  28004\n",
       "4  28005 True     185  ActivityLevel:Moderately A...  28005"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalDataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label:28001 NewUser:True Gender:Other Age:57 H...</td>\n",
       "      <td>28001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>label:28002 NewUser:False Gender:Female Age:62...</td>\n",
       "      <td>28002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label:28003 NewUser:True Gender:Other Age:45 H...</td>\n",
       "      <td>28003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>label:28004 NewUser:False Gender:Other Age:65 ...</td>\n",
       "      <td>28004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>label:28005 NewUser:True Gender:Other Age:46 H...</td>\n",
       "      <td>28005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  label:28001 NewUser:True Gender:Other Age:57 H...  28001\n",
       "1  label:28002 NewUser:False Gender:Female Age:62...  28002\n",
       "2  label:28003 NewUser:True Gender:Other Age:45 H...  28003\n",
       "3  label:28004 NewUser:False Gender:Other Age:65 ...  28004\n",
       "4  label:28005 NewUser:True Gender:Other Age:46 H...  28005"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalDataframe2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training DistilBert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "generalDataframe['label'] = label_encoder.fit_transform(generalDataframe['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split of Data for Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_df, val_df = train_test_split(generalDataframe, test_size=0.001, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function to map label encodings to text tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfClasses=max(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataset=Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfiguredMetric:\n",
    "    def __init__(self, metric, *metric_args, **metric_kwargs):\n",
    "        self.metric = metric\n",
    "        self.metric_args = metric_args\n",
    "        self.metric_kwargs = metric_kwargs\n",
    "    \n",
    "    def add(self, *args, **kwargs):\n",
    "        return self.metric.add(*args, **kwargs)\n",
    "    \n",
    "    def add_batch(self, *args, **kwargs):\n",
    "        return self.metric.add_batch(*args, **kwargs)\n",
    "\n",
    "    def compute(self, *args, **kwargs):\n",
    "        return self.metric.compute(*args, *self.metric_args, **kwargs, **self.metric_kwargs)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.metric.name\n",
    "\n",
    "    def _feature_names(self):\n",
    "        return self.metric._feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading DistilbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "modelBert= AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=numberOfClasses+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding for the dynamic range of text lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/189 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 189/189 [54:33<00:00, 17.32s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3272.9512, 'train_samples_per_second': 0.916, 'train_steps_per_second': 0.058, 'train_loss': 6.91446681754299, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.752269744873047, 'eval_runtime': 0.2808, 'eval_samples_per_second': 3.561, 'eval_steps_per_second': 3.561, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=modelBert,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Distilbert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 164.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.752269744873047, 'eval_runtime': 0.7688, 'eval_samples_per_second': 1.301, 'eval_steps_per_second': 1.301, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "eval_results = trainer.evaluate(tokenized_val_dataset)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split for Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(generalDataframe['text'], generalDataframe['label'], random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode', lowercase=True)\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train_transformed, X_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNb=MultinomialNB()\n",
    "modelNb.fit(X_train_transformed,X_train)\n",
    "predictions=modelNb.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 12).fit(X_train_transformed, X_train)\n",
    "knn_predictions = knn.predict(X_test_transformed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_predict = \"\"\"\n",
    "Gender: Male Age: 94 Height: 170 Weight: 78 ActivityLevel: ModeratelyActive GoalID: 9 DietPreferenceID: 2 RegionID: 10 AllergenID: 10\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def predict_labelDistilbert(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    inputs = {k: v.to(modelBert.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = modelBert(**inputs).logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_label = torch.argmax(probabilities, dim=-1).item()\n",
    "    return label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "def predict_label_id_multinomial_nb(text):\n",
    "    text_transformed = vectorizer.transform([text])\n",
    "    return modelNb.predict(text_transformed)[0]\n",
    "\n",
    "def predict_label_id_svm(text):\n",
    "    text_transformed = vectorizer.transform([text])\n",
    "    return svm_model_linear.predict(text_transformed)[0]\n",
    "\n",
    "def predict_label_id_knn(text):\n",
    "    text_transformed = vectorizer.transform([text])\n",
    "    return knn.predict(text_transformed)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labelDISTILBERT=\"\"\n",
    "predicted_labelDISTILBERT = predict_labelDistilbert(text_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes predicted label ID: 28249 False     170  ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10\n"
     ]
    }
   ],
   "source": [
    "predicted_labelMNB=\"\"\n",
    "predicted_labelMNB= predict_label_id_multinomial_nb(text_to_predict)\n",
    "print(f\"Multinomial Naive Bayes predicted label ID: {predicted_labelMNB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM predicted label ID: 28249 False     170  ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 GoalID:3 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 DietPreferenceID:2 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 RegionID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_labelSVM=\"\"\n",
    "predicted_labelSVM = predict_label_id_svm(text_to_predict)\n",
    "print(f\"SVM predicted label ID: {predicted_labelSVM}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN predicted label ID: 28065 True     161  ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active ActivityLevel:Very Active GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 GoalID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 DietPreferenceID:7 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 RegionID:4 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10 AllergenID:10\n"
     ]
    }
   ],
   "source": [
    "# Predict using KNN\n",
    "predicted_labelKNN = predict_label_id_knn(text_to_predict)\n",
    "print(f\"KNN predicted label ID: {predicted_labelKNN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Extraction for Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading integer for SVM label: 28249\n",
      "Leading integer for KNN label: 28065\n",
      "Leading integer for MNB label: 28249\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example predicted label strings for SVM, KNN, and MNB models\n",
    "predictedLabelSVM = predicted_labelSVM\n",
    "predictedLabelKNN = predicted_labelKNN\n",
    "predictedLabelMNB = predicted_labelMNB\n",
    "\n",
    "# Function to extract the leading integer from a predicted label string\n",
    "def extract_leading_integer_from_label(predicted_label):\n",
    "    match = re.match(r'(\\d+)', predicted_label)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Convert the matched digits to an integer\n",
    "    else:\n",
    "        return None  # Return None if no leading integer is found\n",
    "\n",
    "# Extract leading integers for each predicted label\n",
    "leading_integer_svm = extract_leading_integer_from_label(predictedLabelSVM)\n",
    "leading_integer_knn = extract_leading_integer_from_label(predictedLabelKNN)\n",
    "leading_integer_mnb = extract_leading_integer_from_label(predictedLabelMNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT: 28434\n",
      "SVM: 28249\n",
      "KNN: 28065\n",
      "MNB: 28249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary with model names as keys and their respective values\n",
    "model_values_dict = {\n",
    "    \"DistilBERT\": predicted_labelDISTILBERT,  # This is the predicted label for DistilBERT\n",
    "    \"SVM\": leading_integer_svm,  # This is the leading integer extracted from the SVM predicted label\n",
    "    \"KNN\": leading_integer_knn,  # This is the leading integer extracted from the KNN predicted label\n",
    "    \"MNB\": leading_integer_mnb   # This is the leading integer extracted from the MNB predicted label\n",
    "}\n",
    "\n",
    "# Print the dictionary to verify its contents\n",
    "for model, value in model_values_dict.items():\n",
    "    print(f\"{model}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting relevant part of the text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the text starting from \"Gender\"\n",
    "def extract_text_from_gender(text):\n",
    "    parts = text.split(\"Gender:\")  # Split the text at \"Gender:\"\n",
    "    if len(parts) > 1:\n",
    "        return \"Gender:\" + parts[1]  # Return the part of the text starting from \"Gender:\"\n",
    "    else:\n",
    "        return text  # Return the original text if \"Gender:\" is not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering our Data to Find Corresponding Information To Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Gender:Female Age:48 Height:170 Weight:115 ActivityLevel:Very Active GoalID:3 DietPreferenceID:2 RegionID:10 AllergenID:10\n",
      "DistilBERT: Gender:Male Age:46 Height:174 Weight:79 ActivityLevel:Active GoalID:2 DietPreferenceID:4 RegionID:3 AllergenID:6\n",
      "MNB: Gender:Female Age:48 Height:170 Weight:115 ActivityLevel:Very Active GoalID:3 DietPreferenceID:2 RegionID:10 AllergenID:10\n",
      "KNN: Gender:Male Age:53 Height:161 Weight:115 ActivityLevel:Very Active GoalID:7 DietPreferenceID:7 RegionID:4 AllergenID:10\n",
      "Actual: Gender: Male Age: 94 Height: 170 Weight: 78 ActivityLevel: ModeratelyActive GoalID: 9 DietPreferenceID: 2 RegionID: 10 AllergenID: 10\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for each predicted label and retrieve the corresponding 'text' value\n",
    "\n",
    "# For predicted_labelSVM\n",
    "filtered_df_svm = generalDataframe2.loc[generalDataframe2['label'] == filter_label_value_svm, 'text']\n",
    "corresponding_text_value_svm = extract_text_from_gender(filtered_df_svm.iloc[0]) if not filtered_df_svm.empty else \"No matching text found for the specified label\"\n",
    "\n",
    "# For predicted_labelDISTILBERT\n",
    "filtered_df_distilbert = generalDataframe2.loc[generalDataframe2['label'] == filter_label_value_distilbert, 'text']\n",
    "corresponding_text_value_distilbert = extract_text_from_gender(filtered_df_distilbert.iloc[0]) if not filtered_df_distilbert.empty else \"No matching text found for the specified label\"\n",
    "\n",
    "# For predicted_labelMNB\n",
    "filtered_df_mnb = generalDataframe2.loc[generalDataframe2['label'] == filter_label_value_mnb, 'text']\n",
    "corresponding_text_value_mnb = extract_text_from_gender(filtered_df_mnb.iloc[0]) if not filtered_df_mnb.empty else \"No matching text found for the specified label\"\n",
    "\n",
    "# For predicted_labelKNN\n",
    "filtered_df_knn = generalDataframe2.loc[generalDataframe2['label'] == filter_label_value_knn, 'text']\n",
    "corresponding_text_value_knn = extract_text_from_gender(filtered_df_knn.iloc[0]) if not filtered_df_knn.empty else \"No matching text found for the specified label\"\n",
    "\n",
    "# Print or use the corresponding text values as needed\n",
    "print(\"SVM:\", corresponding_text_value_svm)\n",
    "print(\"DistilBERT:\", corresponding_text_value_distilbert)\n",
    "print(\"MNB:\", corresponding_text_value_mnb)\n",
    "print(\"KNN:\", corresponding_text_value_knn)\n",
    "print(\"Actual:\", extract_text_from_gender(text_to_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluation Of Models (Using Pre-Trained Similarity Calculation Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DistilBERT, Similarity Score: 0.9576306343078613\n",
      "Model: SVM, Similarity Score: 0.9587364792823792\n",
      "Model: MNB, Similarity Score: 0.9587364792823792\n",
      "Model: KNN, Similarity Score: 0.951102614402771\n",
      "\n",
      "The most similar model to the info string is: SVM with text: 'Gender:Female Age:48 Height:170 Weight:115 ActivityLevel:Very Active GoalID:3 DietPreferenceID:2 RegionID:10 AllergenID:10' and a similarity score of: 0.9587364792823792\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Your info string\n",
    "info_string = text_to_predict  # Make sure text_to_predict is defined with your actual text\n",
    "\n",
    "# Dictionary mapping model names to their corresponding text values\n",
    "model_texts = {\n",
    "    \"DistilBERT\": corresponding_text_value_distilbert,\n",
    "    \"SVM\": corresponding_text_value_svm,\n",
    "    \"MNB\": corresponding_text_value_mnb,\n",
    "    \"KNN\": corresponding_text_value_knn\n",
    "}\n",
    "\n",
    "# Filter out empty predicted texts\n",
    "model_texts = {model_name: text for model_name, text in model_texts.items() if text.strip()}\n",
    "\n",
    "# Proceed only if there are non-empty predicted labels\n",
    "if model_texts:\n",
    "    # Encode the info string to get its embedding\n",
    "    info_embedding = model.encode(info_string, convert_to_tensor=True)\n",
    "    \n",
    "    # Initialize a dictionary to store similarity scores for each model\n",
    "    similarity_scores = {}\n",
    "\n",
    "    # Variable to store the text of the most similar model\n",
    "    most_similar_text = None\n",
    "    \n",
    "    # Iterate over each model text, compute its similarity to the info_string, and store it\n",
    "    for model_name, text in model_texts.items():\n",
    "        # Encode the model's text to get its embedding\n",
    "        text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarity_score = util.pytorch_cos_sim(info_embedding, text_embedding).item()\n",
    "        \n",
    "        # Store the similarity score\n",
    "        similarity_scores[model_name] = similarity_score\n",
    "        \n",
    "        # Print the model name and similarity score with the info_string\n",
    "        print(f\"Model: {model_name}, Similarity Score: {similarity_score}\")\n",
    "\n",
    "        # Update the most similar text if this score is the highest\n",
    "        if most_similar_text is None or similarity_score > similarity_scores.get(most_similar_model, 0):\n",
    "            most_similar_model = model_name\n",
    "            most_similar_text = text\n",
    "            highest_similarity_score = similarity_score\n",
    "\n",
    "    # Print the most similar model, its text, and similarity score\n",
    "    print(f\"\\nThe most similar model to the info string is: {most_similar_model} with text: '{most_similar_text}' and a similarity score of: {highest_similarity_score}\")\n",
    "else:\n",
    "    print(\"All predicted labels are empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender: Male Age: 94 Height: 170 Weight: 78 ActivityLevel: ModeratelyActive GoalID: 9 DietPreferenceID: 2 RegionID: 10 AllergenID: 10\n",
      "Gender:Female Age:48 Height:170 Weight:115 ActivityLevel:Very Active GoalID:3 DietPreferenceID:2 RegionID:10 AllergenID:10\n"
     ]
    }
   ],
   "source": [
    "print(text_to_predict)\n",
    "print(most_similar_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
